{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from neuron import MLP\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "DATA_DIR = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data_pos = pd.read_csv(DATA_DIR/'michal'/'pos_trn.csv')\n",
    "trn_data_pos['is_positive'] = 1\n",
    "trn_data_neg = pd.read_csv(DATA_DIR/'michal'/'neg_trn.csv')\n",
    "trn_data_neg['is_positive'] = 0\n",
    "trn_data = pd.concat([trn_data_pos, trn_data_neg], axis=0)\n",
    "trn_data.fillna(-1, inplace=True)\n",
    "shuffled_data = trn_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "VAL_SPLIT = 0.2\n",
    "split_idx = int(VAL_SPLIT * shuffled_data.shape[0])\n",
    "val_data = shuffled_data.iloc[:split_idx]\n",
    "trn_data = shuffled_data.iloc[split_idx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trn_data.drop(columns=['is_positive'])\n",
    "y = trn_data['is_positive']\n",
    "X_val = val_data.drop(columns=['is_positive'])\n",
    "y_val = val_data['is_positive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_val = scaler.transform(X_val)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y.values, dtype=torch.float32).reshape(-1, 1)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X, y)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "              f'Val Loss: {val_loss/len(val_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1, Train Loss: 1.2116, Val Loss: 1.1726\n",
      "Epoch 2, Train Loss: 1.1680, Val Loss: 1.1603\n",
      "Epoch 3, Train Loss: 1.1617, Val Loss: 1.1607\n",
      "Epoch 4, Train Loss: 1.1585, Val Loss: 1.1561\n",
      "Epoch 5, Train Loss: 1.1603, Val Loss: 1.1513\n",
      "Epoch 6, Train Loss: 1.1594, Val Loss: 1.1423\n",
      "Epoch 7, Train Loss: 1.1586, Val Loss: 1.1408\n",
      "Epoch 8, Train Loss: 1.1567, Val Loss: 1.1422\n",
      "Epoch 9, Train Loss: 1.1553, Val Loss: 1.1432\n",
      "Epoch 10, Train Loss: 1.1499, Val Loss: 1.1403\n",
      "Epoch 11, Train Loss: 1.1516, Val Loss: 1.1357\n",
      "Epoch 12, Train Loss: 1.1529, Val Loss: 1.1406\n",
      "Epoch 13, Train Loss: 1.1537, Val Loss: 1.1426\n",
      "Epoch 14, Train Loss: 1.1496, Val Loss: 1.1346\n",
      "Epoch 15, Train Loss: 1.1505, Val Loss: 1.1341\n",
      "Epoch 16, Train Loss: 1.1529, Val Loss: 1.1323\n",
      "Epoch 17, Train Loss: 1.1480, Val Loss: 1.1369\n",
      "Epoch 18, Train Loss: 1.1505, Val Loss: 1.1367\n",
      "Epoch 19, Train Loss: 1.1490, Val Loss: 1.1384\n",
      "Epoch 20, Train Loss: 1.1511, Val Loss: 1.1356\n",
      "Validation Accuracy: 53.17%\n",
      "Confusion matrix:\n",
      "TP: 191, FP: 1047\n",
      "FN: 8, TN: 1007\n",
      "Precision: 0.15\n",
      "Recall: 0.96\n"
     ]
    }
   ],
   "source": [
    "model = MLP(input_size=X.shape[1], hidden_sizes=[64,64], output_size=1)\n",
    "num_pos = y.sum().item()\n",
    "num_neg = y.size(0) - num_pos\n",
    "pos_weight = num_neg / num_pos  # Higher values favor recall over precision\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "print(\"Starting training...\")\n",
    "train_mlp(model, train_loader, val_loader, criterion, optimizer, epochs=20)\n",
    "\n",
    "# Evaluate model on validation set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "pos_prediced = 0\n",
    "all_predicted = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TP = 0\n",
    "TN = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        TP += ((predicted == 1) & (targets == 1)).sum().item()\n",
    "        TN += ((predicted == 0) & (targets == 0)).sum().item()\n",
    "        FP += ((predicted == 1) & (targets == 0)).sum().item()\n",
    "        FN += ((predicted == 0) & (targets == 1)).sum().item()\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        \n",
    "print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "print(f'Confusion matrix:')\n",
    "print(f'TP: {TP}, FP: {FP}')\n",
    "print(f'FN: {FN}, TN: {TN}')\n",
    "print(f'Precision: {TP / (TP + FP):.2f}')\n",
    "print(f'Recall: {TP / (TP + FN):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 52.13%\n"
     ]
    }
   ],
   "source": [
    "pos_tst = pd.read_csv(DATA_DIR/'michal'/'pos_tst.csv')\n",
    "pos_tst['is_positive'] = 1\n",
    "neg_tst = pd.read_csv(DATA_DIR/'michal'/'neg_tst.csv')\n",
    "neg_tst['is_positive'] = 0\n",
    "tst_data = pd.concat([pos_tst, neg_tst], axis=0)\n",
    "tst_data.fillna(-1, inplace=True)\n",
    "tst_data = tst_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "X_tst = tst_data.drop(columns=['is_positive'])\n",
    "y_tst = tst_data['is_positive']\n",
    "X_tst = scaler.transform(X_tst)\n",
    "X_tst = torch.tensor(X_tst, dtype=torch.float32)\n",
    "y_tst = torch.tensor(y_tst.values, dtype=torch.float32).reshape(-1, 1)\n",
    "tst_dataset = TensorDataset(X_tst, y_tst)\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in tst_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
